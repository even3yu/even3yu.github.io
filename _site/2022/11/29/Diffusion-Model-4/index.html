<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>生成扩散模型(四): 扩散模型和得分匹配 (Generative Diffusion Model: Diffusion Matching and Score Matching)</title>
    <meta name="description" content="我们在《生成扩散模型(三): 灵活性和易处理性》一文中讨论了生成扩散模型对前向过程和反向过程的建模, 以及训练模型时所使用的极大化似然函数的推导. 然而先前的扩散模型的生成效果仍然有限, Ho 等人在 DDPM 一文 《Denoising Deffision Probabilistic Models》 中指出扩散...">

    <!-- 网站所有权验证 -->
    <meta name="baidu-site-verification" content="code-kzX4R1yDEi" />
    <meta name="google-site-verification" content="kj0sMKl0iZFsV2KPqmN9OJ3S7aeCrJnNYAOTpJzXCz4" />
    <meta name="msvalidate.01" content="C9A829578EE81A43ECA102B601A5E052" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/css/zui.min.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/2022/11/29/Diffusion-Model-4/">
    <link rel="alternate" type="application/rss+xml" title="Jarvis' Blog (总有美丽的风景让人流连)" href="http://localhost:4000/feed.xml ">


    <script>
    // 百度统计代码
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?b9d127980a49e998bbedb8aab536a81d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    <script>
    // google analytics
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-108096001-2', 'auto');
      ga('send', 'pageview');

    </script>



<script>
window.MathJax = {
  tex: {
    inlineMath: [["$$ "," $$"],["\\(","\\)"]],
    processEscapes: true,
    tags: "all",
    macros: {
      bm: ["{\\boldsymbol #1}",1]
    },
    packages: {'[+]': ['noerrors']}
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
  loader: {
    load: ['input/asciimath', '[tex]/noerrors']
  }
};
</script>
<script async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js" id="MathJax-script">
</script>
<!-- src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> -->



<!--  -->
    
<script type="text/javascript">
    var host = "jarvis73.com";
    if ((host == window.location.host) && (window.location.protocol != "https:"))
      window.location.protocol = "https";
</script>
</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/index.html" class="brand">Jarvis' Blog (总有美丽的风景让人流连)</a>
        <small>总有美丽的风景让人流连</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/index.html">
                    
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/wiki/">
                        
                            <i class="fa fa-book"></i>Wiki
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>Collections
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" post>
    <div class="left-jekyll">
        <h1>生成扩散模型(四): 扩散模型和得分匹配 (Generative Diffusion Model: Diffusion Matching and Score Matching)</h1>
        <div class="label-custom">

            <div class="label-custom-card">
                <i class="fa fa-calendar"></i>2022-11-29
            </div>

            

            <div class="label-custom-card">
                <i class="fa fa-user"></i>Jarvis
                
            </div>

            <div class="label-custom-card">
                <i class="fa fa-key"></i>Post  
            </div>

            <div class="label-custom-card">
            


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#深度学习" title="Category: 深度学习" rel="category">深度学习</a>&nbsp;
    
        <a href="/category/#生成模型" title="Category: 生成模型" rel="category">生成模型</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


            </div>

        </div>
        <hr>
        <article itemscope itemtype="http://schema.org/BlogPosting">
        <ul id="markdown-toc">
  <li><a href="#背景回顾" id="markdown-toc-背景回顾">背景回顾</a></li>
  <li><a href="#扩散模型和去噪得分匹配" id="markdown-toc-扩散模型和去噪得分匹配">扩散模型和去噪得分匹配</a></li>
  <li><a href="#损失函数" id="markdown-toc-损失函数">损失函数</a></li>
  <li><a href="#算法总结" id="markdown-toc-算法总结">算法总结</a></li>
</ul>

<p>我们在<a href="/2022/11/27/Diffusion-Model-3/">《生成扩散模型(三): 灵活性和易处理性》</a>一文中讨论了生成扩散模型对前向过程和反向过程的建模, 以及训练模型时所使用的极大化似然函数的推导. 然而先前的扩散模型的生成效果仍然有限, Ho 等人在 <span style="color:blue">DDPM</span> 一文 <a href="https://arxiv.org/abs/2006.11239">《Denoising Deffision Probabilistic Models》</a> 中指出扩散模型实际上可以生成更高质量的样本. 同时, 扩散模型在选择特定超参数的情况下与 <a href="">去噪得分匹配 (denoising score matching)</a> 的训练过程和基于 <a href="">退火的朗之万动力学(annealed Langevin dynamics)</a> 的采样过程是等价的.</p>

<h2 id="背景回顾">背景回顾</h2>

<p><strong>反向过程</strong> \(\newcommand{\xx}{\bm{x}} \newcommand{\pt}{p_{\theta}} \newcommand{\mt}{\bm{\mu}_{\theta}} \newcommand{\st}{\bm{\Sigma}_{\theta}}\)</p>

<p>扩散模型是个隐变量模型 \(p_{\theta}(\xx_0)\triangleq\int p_{\theta}(\xx_{0:T})d\xx_{1:T}\), 其中 \(\xx_0 \sim q(\xx_0)\) 是观测变量, \(\xx_1,\cdots,\xx_T\) 是隐变量. 其反向过程 \(p_{\theta}(\xx_{0:T})\) 是一个马尔科夫链, 从状态 \(p(\xx_T)=\mathcal{N}(\xx_T;\bm{0},\bm{I})\) 开始, 转移变换 \(p_{\theta}(\xx_{t-1}\vert\xx_t)\) 通过神经网络学习出来, 其中 \(\theta\) 是模型参数:</p>

\[\pt(\xx_T)\prod_{t=1}^T\pt(\xx_{t-1}\vert\xx_t), \quad \pt(\xx_{t-1}\vert\xx_t) \triangleq\mathcal{N}(\xx_{t-1};\mt(\xx_t,t),\st(\xx_t, t)).\]

<p>这里的转移变换 \(\pt(\xx_{t-1}\vert\xx_t)\) 定义为正态分布, 其均值向量 \(\mt(\xx_t,t)\) 和协方差矩阵 \(\st(\xx_t, t)\) 是我们需要通过模型得到的.</p>

<p><strong>前向过程</strong></p>

<p>扩散模型区别于其他隐变量模型的地方在于隐变量的后验概率 \(q(\xx_{1:T}\vert\xx_0)\) 也定义为一个马尔科夫链 (称为扩散过程或者正向过程), 其转移变换为在数据上不断增加方差为 \(\beta_1,\cdots,\beta_T\) 的高斯噪声:</p>

\[\label{eq:transform}
    q(\xx_{1:T}\vert\xx_0) \triangleq \prod_{t=1}^T q(\xx_t\vert\xx_{t-1}), \quad q(\xx_t\vert\xx_{t-1}) \triangleq \mathcal{N}(\xx_t;\sqrt{1-\beta_t}\xx_{t-1}, \beta_t\bm{I}).\]

<p>注意这里 \(\beta_t\) 是接近于 0 的数, 所以正向过程每次只增加一点点高斯噪声, 这有利于模型的学习(只学习简单的去噪任务, 训练可以变得更容易).</p>

<p>前向过程有个特点是, 给定任意 \(\xx_0\), 我们可以直接计算出任意时刻 \(t\) 的条件边际分布 \(q(\xx_t\vert\xx_0)\). 不妨把式 \eqref{eq:transform} 的递推式利用<a href="/2022/09/05/Normal-Distribution/#重参数化技巧">《重参数化技巧》</a>写为</p>

\[\label{eq:reparam}
    \xx_t = \sqrt{\alpha_t}\xx_{t-1} + \sqrt{1-\alpha_t}\bm{\epsilon}_t, \quad \alpha_t \triangleq 1 - \beta_t, \quad \bm{\epsilon}_t\in\mathcal{N}(\bm{0}, \bm{I}).\]

<p>注意 \(q(\xx_t\vert\xx_{t-1})\) 的定义方式使得重参数化后 \(\xx_{t-1}\) 和 \(\bm{\epsilon}\) 的系数的平方和为 \(1\). 这样的定义方式可以便于我们后续的推导. 由此我们可以对式 \eqref{eq:reparam} 自行迭代得到</p>

\[\begin{align}
        \xx_t &amp;= \sqrt{\alpha_t}\xx_{t-1} + \sqrt{1-\alpha_t}\bm{\epsilon}_t \\
        &amp;= \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}\xx_{t-2} + \sqrt{1-\alpha_{t-1}}\bm{\epsilon}_{t-1}) + \sqrt{1-\alpha_t}\bm{\epsilon}_t \\
        &amp;= \sqrt{\alpha_t\alpha_{t-1}}\xx_{t-2} + \underline{\sqrt{\alpha_t(1-\alpha_{t-1})}\bm{\epsilon}_{t-1} + \sqrt{1-\alpha_t}\bm{\epsilon}_t} \\
        &amp;= \sqrt{\alpha_t\alpha_{t-1}}\xx_{t-2} + \sqrt{1-\alpha_{t-1}\alpha_t}\bm{\epsilon}' &amp; {\small 正态分布随机变量的和} \\
        &amp;= \cdots \\
        &amp;= \sqrt{\alpha_t\alpha_{t-1}\cdots\alpha_1}\xx_0 + \sqrt{1-\alpha_t\alpha_{t-1}\cdots\alpha_1}\bm{\epsilon} &amp; {\small 一直迭代直到 \xx_0} \\ \label{eq:xt_x0}
        &amp;= \sqrt{\bar{\alpha}_t}\xx_0 + \sqrt{1-\bar{\alpha}_t}\bm{\epsilon} &amp; {\small \bar{\alpha}_t\triangleq \alpha_t\alpha_{t-1}\cdots\alpha_1}
    \end{align}\]

<p>注意上面划线的部分, 两个服从正态分布的独立随机变量的和仍是个正态分布, 我们不妨把它记为 \(\bm{\epsilon}'\). 其均值仍为 \(0\) , 方差为</p>

\[\begin{align}
        &amp; \left(\sqrt{\alpha_t(1-\alpha_{t-1})}\right)^2 + \left(\sqrt{1-\alpha_t}\right)^2 \\
        =&amp; \alpha_t - \alpha_t\alpha_{t-1} + 1 - \alpha_t \\
        =&amp; 1 - \alpha_{t-1}\alpha_t
    \end{align}\]

<p>详见<a href="/2022/09/05/Normal-Distribution/#正态分布随机变量的和">《正态分布随机变量的和》</a>.</p>

<p>根据式 \eqref{eq:xt_x0}, 反向重参数化后我们有</p>

\[\label{eq:xt_x0_dist}
    q(\xx_t\vert\xx_0) = \mathcal{N}(\xx_t;\sqrt{\bar{\alpha}_t}\xx_0, (1-\bar{\alpha}_t)\bm{I}).\]

<p>这样我们可以直接根据定义的 \(\beta_t\) 序列和采样的 \(\xx_0\), 一次性采样得到 \(\xx_t\).</p>

<p><strong>优化目标</strong></p>

<p>与 Sohl-Dickstein 在 2015 年的工作相同 (见 <a href="/2022/11/27/Diffusion-Model-3/#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">《生成扩散模型(三): 灵活性和易处理性》</a>), DDPM 的优化目标是<u>极小化<strong>负</strong>对数似然</u>:</p>

\[\begin{align}
        &amp;\mathbb{E}_{q(\xx_0)}[-\log\pt(\xx_0)] \\
        =\;&amp; \mathbb{E}_{q(\xx_0)}\left[-\log\int\pt(\xx_{0:T})d\xx_{1:T}\right] &amp; {\small 边际分布 \rightarrow 联合分布} \\
        =\;&amp; \mathbb{E}_{q(\xx_0)}\left[-\log\int\frac{\pt(\xx_{0:T})}{q(\xx_{1:T}\vert\xx_0)}\cdot q(\xx_{1:T}\vert\xx_0)d\xx_{1:T}\right] &amp; {\small 分子分母同乘以前向过程} \\
        =\;&amp; \mathbb{E}_{q(\xx_0)}\left[-\log\mathbb{E}_{q(\xx_{1:T}\vert\xx_0)}\left[\frac{\pt(\xx_{0:T})}{q(\xx_{1:T}\vert\xx_0)}\right] \right] &amp; {\small 积分写成期望} \\
        \leq\;&amp; \mathbb{E}_{q(\xx_0)}\left[\mathbb{E}_{q(\xx_{1:T}\vert\xx_0)}\left[-\log\frac{\pt(\xx_{0:T})}{q(\xx_{1:T}\vert\xx_0)}\right] \right] &amp; {\small 琴生不等式} \\
        =\;&amp; \mathbb{E}_{q(\xx_{0:T})}\left[-\log\frac{\pt(\xx_{0:T})}{q(\xx_{1:T}\vert\xx_0)}\right]
    \end{align}\]

<p>其中的小于等于号是根据 <a href="/2022/11/27/Diffusion-Model-3/#jensen_inequality">琴生不等式(Jensen’s inequality)</a> 的期望形式得到的.</p>

<p>到了这一步, Sohl-Dickstein 是根据交叉熵为常数进行推导的, 最后是以 KL 散度和熵的形式表达的. 而 DDPM 中的推导略有不同 (附录A), 最终为</p>

\[\begin{multline} \label{eq:obj}
        \mathbb{E}_{q(\xx_0)}[\underbrace{\mathbb{KL}(q(\xx_T\vert\xx_0)\Vert p(\xx_T))}_{L_T}] \\
        + \sum_{t=2}^T\mathbb{E}_{q(\xx_0,\xx_t)}[\underbrace{\mathbb{KL}(q(\xx_{t-1}\vert\xx_t,\xx_0)\Vert \pt(\xx_{t-1}\vert\xx_t))}_{L_{t-1}}] \\
         - \mathbb{E}_{q(\xx_1)}[\underbrace{\log\pt(\xx_0\vert\xx_1)}_{L_0}]
    \end{multline}\]

<p>注意论文中把三个期望统一写成了 \(\mathbb{E}_q\) 了, 会让人比较困惑, 我们这里还是分开写.</p>

<p>下面我们考虑式 \eqref{eq:obj} 中各项的易处理性. \(L_T\) 的 \(q(\xx_T\vert\xx_0)\) 和 \(p(\xx_T)\) 都有确切表达式; \(L_0\) 中的 \(\pt(\xx_0\vert\xx_1)\) 可以由模型给出; \(L_{1:T-1}\) 中的 \(\pt(\xx_{t-1}\vert\xx_t)\) 也可以由模型给出, 最后只剩 \(q(\xx_{t-1}\vert\xx_t,\xx_0)\). 我们发现, 尽管 \(q(\xx_{t-1}\vert\xx_t)\) 是不易处理的 (用 Bayes 公式变换得到 \(q(\xx_{t-1}\vert\xx_t)=\frac{q(\xx_t\vert\xx_{t-1})p(\xx_{t-1})}{p(\xx_t)}\), 但 \(p(\xx_t)\) 和 \(p(\xx_{t-1})\) 都不易获得), 但我们知道如果以 \(\xx_0\) 为条件的话, \(p(\xx_t\vert\xx_0)\) 和 \(p(\xx_{t-1}\vert\xx_0)\) 都是有确切表达式的 (式 \eqref{eq:xt_x0} 或 \eqref{eq:xt_x0_dist}). 因此我们考虑用 Bayes 公式来计算:</p>

\[\begin{align}
        q(\xx_{t-1}\vert\xx_t,\xx_0) &amp;= \frac{q(\xx_t\vert\xx_{t-1},\xx_0)q(\xx_{t-1}\vert\xx_0)}{p(\xx_t\vert\xx_0)} \\  \label{eq:xtm1_xt_x0}
        &amp;= \frac{q(\xx_t\vert\xx_{t-1})q(\xx_{t-1}\vert\xx_0)}{q(\xx_t\vert\xx_0)} &amp; {\small 前向过程是马尔科夫的, \xx_0 可以省略}
    \end{align}\]

<p>下面我们把式 \eqref{eq:transform} 和式 \eqref{eq:xt_x0_dist} 高斯分布的密度函数代入式子 \eqref{eq:xtm1_xt_x0} 得到:</p>

\[\begin{align}
        &amp; q(\xx_{t-1}\vert\xx_t,\xx_0) = \frac{q(\xx_t\vert\xx_{t-1})q(\xx_{t-1}\vert\xx_0)}{q(\xx_t\vert\xx_0)} \\ \label{eq:density}
        &amp;= C_1\cdot\exp\left(-\frac12\left(
            \frac{\Vert\xx_t-\sqrt{1-\beta_t}\xx_{t-1}\Vert^2_2}{\beta_t}
            + \frac{\Vert\xx_{t-1}-\sqrt{\bar{\alpha}_{t-1}}\xx_0\Vert^2_2}{1-\bar{\alpha}_{t-1}}
            - \frac{\Vert\xx_t-\sqrt{\bar{\alpha}_t}\xx_0\Vert^2_2}{1-\bar{\alpha}_t}
        \right)\right) \\
        &amp;\triangleq C_2\cdot\exp\left(-\frac{(\xx_{t-1} - \tilde{\bm{\mu}}_t)^2}{2\tilde{\beta}_t}\right)
    \end{align}\]

<p>可以看到式 \eqref{eq:density} 除去常数 \(C_1\), 指数和 \(-\frac12\), 里面的部分是 \(\xx_{t-1}\) 的二次函数, 这符合正态分布的形式, 所以我们直接通过待定系数法可以解出 \(\tilde{\bm{\mu}}_t\) 和 \(\tilde{\beta}_t\) 的表达式如下 (注意用到了前面定义的 \(\alpha_t=1-\beta_t\) 和 \(\bar{\alpha}_t=\bar{\alpha}_{t-1}\cdot\alpha_t\)):</p>

\[\label{eq:tilde_mu_t}
    \tilde{\bm{\mu}}_t = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\xx_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\xx_0, \quad \tilde{\beta}_t = \frac{1-\bar{\alpha}_{t - 1}}{1-\bar{\alpha}_t}\beta_t\]

<p>因此我们有</p>

\[q(\xx_{t-1}\vert\xx_t,\xx_0) = \mathcal{N}(\xx_{t-1}; \tilde{\bm{\mu}}_t(\xx_t,\xx_0), \tilde{\beta}_t\bm{I})\]

<h2 id="扩散模型和去噪得分匹配">扩散模型和去噪得分匹配</h2>

<p>扩散模型在实现时需要定义一些东西: (1) 前向过程的方差序列 \(\beta_t\), (2) 模型结构, (3) 反向过程高斯模型的参数化方式. 本文从去噪得分匹配模型得到启发, 给出了一种更实用的训练目标. 下面依次讨论式 \eqref{eq:obj} 的三个部分 \(L_0, L_{1:T-1}\), 和 \(L_T\) .</p>

<p><strong>前向过程和 \(L_T\)</strong></p>

<p>DDPM 中固定了方差序列 \(\beta_t\) 为常量 (Sohl-Dickstein 使用的是可训练的序列). 此外, 从式 \eqref{eq:obj} 中我们可以看到这一项的 KL 散度计算不依赖于任何的参数 (\(q(\xx_T\vert\xx_0)\) 是预定义好的前向过程, \(p(\xx_T)\) 是标准正态分布), 因此损失函数中可以直接去掉这一项.</p>

<p><strong>反向过程和 \(L_{1:T-1}\)</strong></p>

<p>现在考虑 \(\pt(\xx_{t-1}\vert\xx_t)=\mathcal{N}(\xx_{t-1};\mt(\xx_t,t),\st(\xx_t,t))\) 在 \(1&lt;t&lt;T\) 时模型的定义方式.</p>

<p>首先, DDPM 中把协方差矩阵 \(\st(\xx_t,t)\triangleq\sigma_t^2\bm{I}\) 定义仅依赖时间步 \(t\) 的常量. 作者实验了 \(\sigma^2_t=\beta_t\) 和 \(\sigma^2_t=\tilde{\beta}_t\) 这两种策略, 发现效果差不多. 特别地, 这两种情况分别是 \(\xx_0\sim\mathcal{\bm{0},\bm{I}}\) 和 \(\xx_0\) 只有一个点这两种情况的最优解, 这两种 \(\sigma^2\) 的选择实际上对应了反向过程熵上下界.</p>

<p>其次, 我们考虑均值向量 \(\mt(\xx_t,t)\). 由于 \(q(\xx_{t-1}\vert\xx_t,\xx_0)\) 和 \(\pt(\xx_{t-1}\vert\xx_t))\) 都是正态分布, 根据 <a href="/2022/09/05/Normal-Distribution/#正态分布的-kl-散度">《正态分布的 KL 散度》</a>, 我们有</p>

\[\label{eq:L_tm1}
    L_{t-1} = \mathbb{E}_{q(\xx_0,\xx_t)}\left[\frac1{2\sigma^2_t}\Vert \tilde{\bm{\mu}}_t(\xx_t,\xx_0) - \mt(\xx_t,t) \Vert^2_2\right] + C\]

<p>其中 \(C\) 是只跟方差有关的一个常数, 不依赖于 \(\theta\). 所以我们可以把模型定义为 \(\mt\), 然后来预测 \(\tilde{\bm{\mu}}_t\). 但是这样我们需要同时采样 \(\xx_0\) 和 \(\xx_t\) 才能得到 \(\tilde{\bm{\mu}}_t\) (式 \eqref{eq:tilde_mu_t}), 涉及到两次随机采样, 这样会使得模型训练变得困难. 我们注意到 \(\xx_0\) 可以用 \(\xx_t\) 表示, 因此把式 \eqref{eq:xt_x0} 做个变形得到</p>

\[\xx_0=\frac1{\sqrt{\bar{\alpha}_t}}(\xx_t - \sqrt{1-\bar{\alpha}_t}\bm{\epsilon}),\]

<p>然后代入式 \eqref{eq:tilde_mu_t}, 有</p>

\[\tilde{\bm{\mu}}_t(\xx_t,\xx_0) = \frac1{\sqrt{\alpha}_t}\left(\xx_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}\right).\]

<p>而 \(\mt\) 也依赖于 \(\xx_t\), 那么如果定义为跟上式一样的形式, 即</p>

\[\label{eq:before_sampling}
    \mt(\xx_t,t) = \frac1{\sqrt{\alpha}_t}\left(\xx_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}_{\theta}(\xx_t,t)\right).\]

<p>那么式 \eqref{eq:L_tm1} 就可以变成:</p>

\[L_{t-1} = \mathbb{E}_{q(\xx_0),\bm{\epsilon}\sim\mathcal{N}(\bm{0},\bm{I})}\left[\frac{\beta_t^2}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)}\Vert \bm{\epsilon} - \bm{\epsilon}_{\theta}(\xx_t,t) \Vert^2_2\right] + C.\]

<p>从而这一项损失可以变为</p>

\[\label{eq:L_tm1_final}
    \mathbb{E}_{q(\xx_0),\bm{\epsilon}\sim\mathcal{N}(\bm{0},\bm{I})}\left[\frac{\beta_t^2}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)}\Vert \bm{\epsilon} - \bm{\epsilon}_{\theta}(\sqrt{\bar{\alpha}_t}\xx_0 + \sqrt{1-\bar{\alpha}_t}\bm{\epsilon},t) \Vert^2_2\right].\]

<p>注意上式中的两处 \(\bm{\epsilon}\) 都是从 \(\xx_0\) 生成 \(\xx_t\) 时加的随机噪声, 因此它们可以用一次相同的采样.</p>

<p><strong>去噪得分匹配</strong></p>

<p>现在我们需要的结论都有了, 再看一下和去噪得分匹配的关系. 我们考虑反向过程, 在给定 \(\xx_t\) 时, 我们采样 \(\xx_{t-1}\sim \pt(\xx_{t-1}\vert\xx_t)\) 的过程 (经过重参数化) 其实就是计算式 \eqref{eq:before_sampling} 加上一个高斯噪声, 即</p>

\[\label{eq:sampling}
    \xx_{t-1} = \frac1{\sqrt{\alpha}_t}\left(\xx_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}_{\theta}(\xx_t,t)\right) + \sigma_t\bm{z},\quad \bm{z}\sim\mathcal{N}(\bm{0},\bm{I}).\]

<p>如果我们把 \(\bm{\epsilon}_{\theta}\) 看作学习数据分布的梯度的话, 那么这个过程就和朗之万动力学采样类似了. 同时, 式 \eqref{eq:L_tm1_final} 的形式和多尺度噪声下的去噪得分匹配的形式也是一样的.</p>

<p><strong>数据缩放, 反向过程解码器和 \(L_0\)</strong></p>

<p>由于后面直接把 \(L_0\) 近似简化了, 并且效果不错. 所以这部分略显复杂的近似方案就略去了.</p>

<h2 id="损失函数">损失函数</h2>

<p>DDPM 把最终的训练损失函数简化为</p>

\[\label{eq:loss}
    L_{\text{simple}}(\theta) \triangleq \mathbb{E}_{t,q(\xx_0),\bm{\epsilon}\sim\mathcal{N}(\bm{0},\bm{I})}\left[\Vert \bm{\epsilon} - \bm{\epsilon}_{\theta}(\sqrt{\bar{\alpha}_t}\xx_0 + \sqrt{1-\bar{\alpha}_t}\bm{\epsilon},t) \Vert^2_2\right]\]

<p>其中 \(t=1,2,\cdots,T\). 那么 \(t=1\) 的情况就对应了 \(L_0\) 中的复杂的近似方案; \(1&lt;t\leq T\) 就对应了 \(L_{1:T-1}\) 的情况, 而 \(L_T\) 由于没有可训练的参数, 直接略去了.</p>

<p>注意式子 \eqref{eq:loss} 相比于 \eqref{eq:L_tm1_final} 还去掉了系数 \(\frac{\beta_t^2}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)}\), 这样带来的效果就相当于使用 \(\bm{\epsilon}_{\theta}\) 重构 \(\bm{\epsilon}\) 时对不同的时间步 \(t\) 使用了不同的权重. DDPM 中对这些参数的设置使得, 在 \(t\) 较小时权重也较小, 从而可以让模型重点优化更困难的去噪步 (\(t\) 比较大的时候, 即模型从高斯噪声初步生成目标轮廓的时候).</p>

<h2 id="算法总结">算法总结</h2>

<ul>
  <li>准备数据集: 相当于准备了 \(q(\xx_0)\) 的一组子集</li>
  <li>构建模型, 论文中采用改进的 U-Net 结构: 相当于建模了 \(\bm{\epsilon}_{\theta}(\cdot, \cdot)\)</li>
  <li>执行训练循环:</li>
</ul>

<blockquote>
  <p>\(\text{for } \_ \text{ in range(total_steps)}:\)<br />
\(\quad \xx_0\sim q(\xx_0)\) <br />
\(\quad t\sim \text{Uniform}(\{1,\dots,T\})\) <br />
\(\quad \bm{\epsilon}\sim\mathcal{N}(\bm{0},\bm{I})\) <br />
\(\quad\) 梯度更新:<br />
\(\qquad \nabla_{\theta}\Vert \bm{\epsilon} - \bm{\epsilon}_{\theta}(\sqrt{\bar{\alpha}_t}\xx_0 + \sqrt{1-\bar{\alpha}_t}\bm{\epsilon},t) \Vert^2_2 \qquad\)   (式 \eqref{eq:loss})</p>
</blockquote>

<ul>
  <li>生成模型采样:</li>
</ul>

<blockquote>
  <p>\(\xx_T\sim\mathcal{N}(\bm{0},\bm{I})\)<br />
\(\text{for } t \text{ in range} (T, 0):\)<br />
\(\quad \bm{z}\sim\mathcal{N}(\bm{0},\bm{I}) \text{ if } t &gt; 1, \text{ else } \bm{z}=0\) <br />
\(\quad \xx_{t-1} = \frac1{\sqrt{\alpha}_t}\left(\xx_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}_{\theta}(\xx_t,t)\right) + \sigma_t\bm{z} \qquad\)   (式 \eqref{eq:sampling}) <br />
\(\text{Return } \xx_0\)</p>
</blockquote>

        </article>
        <hr>

        <!-- 
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
         -->

        <div class="post-recent">
    <div class="pre">
        
        <p><strong>上一篇</strong> <a href="/2022/11/27/Diffusion-Model-3/">生成扩散模型(三): 灵活性和易处理性 (Generative Diffusion Model: Flexibility and Tractability)</a></p>
        
    </div>
    <div class="nex">

        
        <p><strong>下一篇</strong> <a href="/2022/12/09/Generative-Model-Metrics/">生成模型指标 (Metrics of Generative Models)</a></p>
        
    </div>
</div>


        <!-- <h2 id="comments">Comments</h2>
        



 -->


    </div>
    <button class="anchor"><i class="fa fa-anchor"></i></button>
    <div class="right-jekyll">
        <div class="wrap">

            <!-- Content -->
            <div class="side content">
                <div>
                    Content
                </div>
                <ul id="content-side" class="content-ul">
                    
                    <li><a href="#comments">Comments</a></li>
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <!-- <div class="side">bbbb</div> -->
        </div>
    </div>
</div>
<script>
/**
 * target _blank
 */
(function() {
    var aTags = document.querySelectorAll('article a:not([id]):not([class])')
    for (var i = 0; i < aTags.length; i++) {
        if (aTags[i].getAttribute('href').startsWith('#'))
        {
            continue
        }
        aTags[i].setAttribute('target', '_blank')
    }
}());
</script>
<script src="/js/pageContent.js " charset="utf-8"></script>

    <footer class="site-footer">


    <div class="wrapper">

        <p class="contact">
            联系我: 
            <a href="https://github.com/jarvis73" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:zjw.math@qq.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>   
            <a href="https://www.zhihu.com/people/lin-xi-1-1" title="Zhihu"><i class="iconfont icon-daoruzhihu"></i></a>      
        </p>
        <p>
            <i class="fa fa-eye" style="padding-right: 2px;"></i> 访问量: <span id="busuanzi_value_site_pv"></span>次 | <i class="fa fa-user" style="padding-right: 2px;"></i> 访客数<span id="busuanzi_value_site_uv"></span>人次
        </p>
        <p class="power">
            网站支持 <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a> | 主题支持 <a href="https://github.com/Gaohaoyang/gaohaoyang.github.io">HyG</a> & <a href="https://github.com/Jarvis73/jarvis73.github.io">Jarvis73</a>
        </p>
        <p>
            <img src="/images/misc/beian.png" style="padding-right: 2px; padding-bottom: 4px; vertical-align: middle;" /> <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo" class="beian" >浙公网安备 33010602011353号 | </a>
            <a target="_blank" href="https://beian.miit.gov.cn/" class="beian">浙ICP备2020038513号-1</a>
        </p>
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script type='text/javascript' src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"></script>
    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/lib/jquery/jquery.js" charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/js/zui.min.js" charset="utf-8"></script>
    <script src="/js/index_page.js" charset="utf-8"></script>
    <script src="/js/functions.js" charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
  </body>

</html>
