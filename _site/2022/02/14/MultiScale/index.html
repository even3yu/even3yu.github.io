<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>多尺度上下文信息 (Multi-Scale Context)</title>
    <meta name="description" content="上下文信息 (context), 长期依赖 (long-range dependencies), 注意力 (attention) 这些概念提出的目的都是希望我们的特征能够在卷积等局部操作的基础上, 更多的吸收图像全局的信息, 从而提高特征的判别性. 这些概念一开始在 NLP 任务中得到了广泛的思考, 比如 LST...">

    <!-- 网站所有权验证 -->
    <meta name="baidu-site-verification" content="code-kzX4R1yDEi" />
    <meta name="google-site-verification" content="kj0sMKl0iZFsV2KPqmN9OJ3S7aeCrJnNYAOTpJzXCz4" />
    <meta name="msvalidate.01" content="C9A829578EE81A43ECA102B601A5E052" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/css/zui.min.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/2022/02/14/MultiScale/">
    <link rel="alternate" type="application/rss+xml" title="Jarvis' Blog (总有美丽的风景让人流连)" href="http://localhost:4000/feed.xml ">


    <script>
    // 百度统计代码
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?b9d127980a49e998bbedb8aab536a81d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    <script>
    // google analytics
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-108096001-2', 'auto');
      ga('send', 'pageview');

    </script>



<script>
window.MathJax = {
  tex: {
    inlineMath: [["$$ "," $$"],["\\(","\\)"]],
    processEscapes: true,
    tags: "all",
    macros: {
      bm: ["{\\boldsymbol #1}",1]
    },
    packages: {'[+]': ['noerrors']}
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
  loader: {
    load: ['input/asciimath', '[tex]/noerrors']
  }
};
</script>
<script async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js" id="MathJax-script">
</script>
<!-- src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> -->



<!--  -->
    
<script type="text/javascript">
    var host = "jarvis73.com";
    if ((host == window.location.host) && (window.location.protocol != "https:"))
      window.location.protocol = "https";
</script>
</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/index.html" class="brand">Jarvis' Blog (总有美丽的风景让人流连)</a>
        <small>总有美丽的风景让人流连</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/index.html">
                    
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/wiki/">
                        
                            <i class="fa fa-book"></i>Wiki
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>Collections
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" post>
    <div class="left-jekyll">
        <h1>多尺度上下文信息 (Multi-Scale Context)</h1>
        <div class="label-custom">

            <div class="label-custom-card">
                <i class="fa fa-calendar"></i>2022-02-14
            </div>

            

            <div class="label-custom-card">
                <i class="fa fa-user"></i>Jarvis
                
            </div>

            <div class="label-custom-card">
                <i class="fa fa-key"></i>Post  
            </div>

            <div class="label-custom-card">
            


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#图像分割" title="Category: 图像分割" rel="category">图像分割</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


            </div>

        </div>
        <hr>
        <article itemscope itemtype="http://schema.org/BlogPosting">
        <ul id="markdown-toc">
  <li><a href="#1-概念" id="markdown-toc-1-概念">1. 概念</a></li>
  <li><a href="#2-non-local-operation" id="markdown-toc-2-non-local-operation">2. Non-Local Operation</a>    <ul>
      <li><a href="#21-二元函数-fcdot-cdot" id="markdown-toc-21-二元函数-fcdot-cdot">2.1 二元函数 \(f(\cdot, \cdot)\)</a></li>
    </ul>
  </li>
  <li><a href="#3-aspp-pspnet" id="markdown-toc-3-aspp-pspnet">3. ASPP, PSPNet</a></li>
  <li><a href="#4-self-attention" id="markdown-toc-4-self-attention">4. Self-Attention</a></li>
  <li><a href="#5-object-context-representation-ocr" id="markdown-toc-5-object-context-representation-ocr">5. Object-Context Representation (OCR)</a>    <ul>
      <li><a href="#51-object-区域的表示" id="markdown-toc-51-object-区域的表示">5.1 Object 区域的表示</a></li>
      <li><a href="#52-ocr" id="markdown-toc-52-ocr">5.2 OCR</a></li>
      <li><a href="#53-增广的特征表示" id="markdown-toc-53-增广的特征表示">5.3 增广的特征表示</a></li>
    </ul>
  </li>
  <li><a href="#6-criss-cross-attention-cca" id="markdown-toc-6-criss-cross-attention-cca">6. Criss-Cross Attention (CCA)</a></li>
  <li><a href="#参考文献" id="markdown-toc-参考文献">参考文献</a></li>
</ul>

<h2 id="1-概念">1. 概念</h2>

<p><strong>上下文信息 (context), 长期依赖 (long-range dependencies), 注意力 (attention)</strong> 这些概念提出的目的都是希望我们的特征能够在卷积等局部操作的基础上, 更多的吸收图像全局的信息, 从而提高特征的判别性. 这些概念一开始在 NLP 任务中得到了广泛的思考, 比如 LSTM, Attention 机制 (因为自然语言是天然的序列, 长距离的特征依赖尤为明显), 而近年来人们发现在 CV 中对这些概念的扩展和应用也能极大的提高特征的表达能力.</p>

<p>早期的长期依赖都是通过不断地重复局部操作来实现的, 比如两个典型的例子:</p>

<ul>
  <li>CNN 中, 通过多层卷积和下采样可以扩大高层卷积核的感受野</li>
  <li>RNN 中, 通过多次重复循环单元实现远距离信息的融合</li>
</ul>

<h2 id="2-non-local-operation">2. Non-Local Operation</h2>

<p>Non-Local 操作的一般形式是 Non-Local Network<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">1</a></sup> 提出的:</p>

\[\mathcal{y}_i = \frac1{\mathcal{C}(\mathbf{x})}\sum_{\forall j}f(\mathbf{x}_i, \mathbf{x}_j)g(\mathbf{x}_j),\]

<p>其中 \(f(\cdot, \cdot)\) 是二元函数, 用于计算 \(\mathcal{x}_i\) 和 \(\mathcal{x}_j\) 的相似度, \(g(\cdot)\) 是一个单元函数, 用于将 \(\mathcal{x}_i\) 投影到一个嵌入空间中计算新的特征.</p>

<h4 id="21-二元函数-fcdot-cdot">2.1 二元函数 \(f(\cdot, \cdot)\)</h4>

<p>该函数的一个基本性质是, 两个元素越相似, 函数值越大.</p>

<ul>
  <li>
    <p><strong>高斯函数:</strong></p>

\[f(\mathbf{x}_i, \mathbf{x_j}) = e^{\mathbf{x}_i^T\mathbf{x}_j}.\]
  </li>
  <li>
    <p><strong>嵌入的高斯函数:</strong></p>

\[f(\mathbf{x}_i, \mathbf{x}_j) = e^{\theta(\mathbf{x}_i)^T\phi(\mathbf{x}_j)}.\]

    <p>这里的 \(\theta(\mathbf{x}_i)\) 和 \(\phi(\mathbf{x}_j)\) 可以是线性映射, 也可以是其他的复杂函数.</p>
  </li>
</ul>

<div class="alert alert-info with-icon card">

<i class="icon-info-sign"></i>
<div class="zui-card-content">

<div class="title"><strong>提示</strong></div><hr />

<div class="content">
      <p>这里的 Non-Local 和 Self-Attention 就差一个归一化.</p>
    </div>

</div>
</div>

<ul>
  <li>
    <p><strong>点积:</strong></p>

\[f(\mathbf{x}_i, \mathbf{x}_j) = \theta(\mathbf{x}_i)^T\phi(\mathbf{x}_j).\]
  </li>
  <li>
    <p><strong>拼接:</strong></p>

\[f(\mathbf{x}_i, \mathbf{x}_j) = \text{ReLU}(\mathbf{w}^T_f[\theta(\mathbf{x}_i), \phi(\mathbf{x}_j)]).\]
  </li>
</ul>

<h2 id="3-aspp-pspnet">3. ASPP, PSPNet</h2>

<p>在语义分割任务中, 在高层特征进行分类时, 结合<strong>多尺度的上下文 (Multi-Scale Context)</strong>信息是极其重要的. 目前比较流行的方法有:</p>

<ul>
  <li><strong>ASPP<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">2</a></sup>:</strong> 通过一系列并行的不同膨胀率的膨胀卷积实现. 详见 <a href="/2019/01/02/DeepLab/">DeepLab 系列</a>.</li>
  <li><strong>PSPNet<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">3</a></sup>:</strong> 通过 Pyramid Pooling Module 在不同尺度的特征图上做常规卷积来捕获多尺度信息, 但是损失了特征图的精度. 详见 <a href="/2022/02/11/PSP/">PSPNet 系列</a>.</li>
</ul>

<h2 id="4-self-attention">4. Self-Attention</h2>

<p>Self-Attention<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">4</a></sup> 通过计算目标 pixel 和其他所有 pixels 之间的关系作为 attention map (权重), 再通过特征的加权和来吸收上下文的信息.</p>

\[\label{eq:ocr}
  \mathbf{y}_i = \rho(\sum_{s\in\mathcal{I}} w_{is}\delta(\mathbf{x}_s))\]

<p>其中 \(w_{is}\) 是像素 \(\mathbf{x}_i\) 和 \(\mathbf{x}_s\) 的关系. 详见 <a href="/2018/01/24/LSTM-Learn/#5-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-attention-mechanism">注意力机制</a>.</p>

<h2 id="5-object-context-representation-ocr">5. Object-Context Representation (OCR)</h2>

<p>OCR<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">5</a></sup> 的 motivation 是表示图像中不同的 object, 然后每个 pixel 从 objects 的表示中吸收信息.</p>

<div class="polaroid">
    
    
    
    <img data-toggle="lightbox" src="/images/2022/02/OCRNet.png" data-caption="Illustrating the pipeline of OCR. (i) form the soft object regions in the pink dashed box. (ii) estimate the object region representations in the purple dashed box; (iii) compute the object contextual representations and the augmented representations in the orange dashed box." />
    
        
        <div class="container">
            <p>图 1. Illustrating the pipeline of OCR. (i) form the soft object regions in the pink dashed box. (ii) estimate the object region representations in the purple dashed box; (iii) compute the object contextual representations and the augmented representations in the orange dashed box.</p>
        </div>
    
</div>

<h4 id="51-object-区域的表示">5.1 Object 区域的表示</h4>

<p>计算每个 pixel 属于某个 object 的权重, 然后把所有 pixel 的特征向量加权和作为 object 的表示:</p>

\[\mathbf{f}_k = \sum_{i\in\mathcal{I}} \tilde{m}_{ki}\mathbf{x}_i,\]

<p>其中 \(\mathbf{x}_i\) 是像素 \(p_i\) 的特征, \(\tilde{m}_{ki}\) 是归一化过(spatial softmax)的像素 \(p_i\) 属于 object \(k\) 的权重.</p>

<h4 id="52-ocr">5.2 OCR</h4>

<p>计算 pixel 的特征到 object 特征的关系:</p>

\[w_{ik} = \frac{e^{\kappa(\mathbf{x}_i, \mathbf{f}_k)}}{\sum_{j=1}^K e^{\kappa(\mathbf{x}_i, \mathbf{f}_j)}}\]

<p>其中 \(\kappa(\mathbf{x}, \mathbf{f}) = \phi(\mathbf{x})\psi(\mathbf{f})\) 用于计算两个特征向量的相似度, \(\phi, \psi\) 为变换函数, 实现为 \(1\times1 \text{ conv} \rightarrow \text{BN} \rightarrow \text{ReLU}\).</p>

<p>然后通过公式 \(\eqref{eq:ocr}\) 计算 \(p_i\) 的 OCR 表示 \(\mathbf{y}_i\).</p>

<h4 id="53-增广的特征表示">5.3 增广的特征表示</h4>

<p>最后把像素 \(p_i\) 原来的特征和 OCR 特征拼接起来作为增广的特征表示:</p>

\[\mathbf{z}_i = g(\text{cat}(\mathbf{x}_i, \mathbf{y}_i)),\]

<p>其中 \(\text{cat}(\cdot,\cdot)\) 为拼接操作, \(g(\cdot)\) 为变换函数.</p>

<h2 id="6-criss-cross-attention-cca">6. Criss-Cross Attention (CCA)</h2>

<p>由于 Self-Attention 需要计算特征图中所有 pixel 之间的关系, 所以需要 \(\mathcal{O}(N^2)\) 的复杂度, \(N\) 为特征图的大小. CCNet<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">6</a></sup> 为降低计算复杂度, 提出了 CCA, 只在目标 pixel 的水平和垂直两个方向计算 attention, 然后循环两个 CCA 模块来实现全图的 attention.</p>

<div class="polaroid-script">
    
    
    
    <img data-toggle="lightbox" src="/images/2022/02/CCNet.png" data-caption="Illustrating the pipeline of CCA." />
    
        
        <div class="container">
            <p>图 2. Illustrating the pipeline of CCA.</p>
        </div>
    
</div>

<p>CCA 的复杂度为 \(\mathcal{O}(N\sqrt{N})\).</p>

<h2 id="参考文献">参考文献</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:2" role="doc-endnote">

      <p><strong>Non-local neural networks</strong>&gt;<br /> 
Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He<br />
<a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper">[html]</a> In CVPR 2018 <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">

      <p><strong>DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</strong> <br />
Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. <br />
<a href="http://arxiv.org/abs/1606.00915">[html]</a>. In TPAMI 2017. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">

      <p><strong>Pyramid Scene Parsing Network</strong><br /> 
Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia<br />
<a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Zhao_Pyramid_Scene_Parsing_CVPR_2017_paper.html">[html]</a> In CVPR 2017 <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">

      <p><strong>Attention is all you need</strong> <br />
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin <br />
<a href="https://arxiv.org/abs/1706.03762">[html]</a> In NeurIPS 2017 <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">

      <p><strong>Segmentation Transformer: Object-Contextual Representations for Semantic Segmentation</strong><br /> 
Yuhui Yuan, Xiaokang Chen, Xilin Chen, and Jingdong Wang<br />
<a href="http://arxiv.org/abs/1909.11065">[html]</a> In ECCV 2020 <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">

      <p><strong>CCNet: Criss-Cross Attention for Semantic Segmentation</strong>&gt;<br /> 
Zilong Huang, Xinggang Wang, Yunchao Wei, Lichao Huang, Humphrey Shi, Wenyu Liu, Thomas S. Huang<br />
<a href="https://arxiv.org/abs/1811.11721">[html]</a> In ICCV 2019 and TPAMI 2020 <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

        </article>
        <hr>

        <!-- 
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
         -->

        <div class="post-recent">
    <div class="pre">
        
        <p><strong>上一篇</strong> <a href="/2022/02/11/PSP/">PSPNet: Segmentation Network</a></p>
        
    </div>
    <div class="nex">

        
        <p><strong>下一篇</strong> <a href="/2022/02/17/MLExpManage/">MongoDB + Omniboard 实验管理</a></p>
        
    </div>
</div>


        <!-- <h2 id="comments">Comments</h2>
        



 -->


    </div>
    <button class="anchor"><i class="fa fa-anchor"></i></button>
    <div class="right-jekyll">
        <div class="wrap">

            <!-- Content -->
            <div class="side content">
                <div>
                    Content
                </div>
                <ul id="content-side" class="content-ul">
                    
                    <li><a href="#comments">Comments</a></li>
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <!-- <div class="side">bbbb</div> -->
        </div>
    </div>
</div>
<script>
/**
 * target _blank
 */
(function() {
    var aTags = document.querySelectorAll('article a:not([id]):not([class])')
    for (var i = 0; i < aTags.length; i++) {
        if (aTags[i].getAttribute('href').startsWith('#'))
        {
            continue
        }
        aTags[i].setAttribute('target', '_blank')
    }
}());
</script>
<script src="/js/pageContent.js " charset="utf-8"></script>

    <footer class="site-footer">


    <div class="wrapper">

        <p class="contact">
            联系我: 
            <a href="https://github.com/jarvis73" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:zjw.math@qq.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>   
            <a href="https://www.zhihu.com/people/lin-xi-1-1" title="Zhihu"><i class="iconfont icon-daoruzhihu"></i></a>      
        </p>
        <p>
            <i class="fa fa-eye" style="padding-right: 2px;"></i> 访问量: <span id="busuanzi_value_site_pv"></span>次 | <i class="fa fa-user" style="padding-right: 2px;"></i> 访客数<span id="busuanzi_value_site_uv"></span>人次
        </p>
        <p class="power">
            网站支持 <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a> | 主题支持 <a href="https://github.com/Gaohaoyang/gaohaoyang.github.io">HyG</a> & <a href="https://github.com/Jarvis73/jarvis73.github.io">Jarvis73</a>
        </p>
        <p>
            <img src="/images/misc/beian.png" style="padding-right: 2px; padding-bottom: 4px; vertical-align: middle;" /> <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo" class="beian" >浙公网安备 33010602011353号 | </a>
            <a target="_blank" href="https://beian.miit.gov.cn/" class="beian">浙ICP备2020038513号-1</a>
        </p>
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script type='text/javascript' src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"></script>
    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/lib/jquery/jquery.js" charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/js/zui.min.js" charset="utf-8"></script>
    <script src="/js/index_page.js" charset="utf-8"></script>
    <script src="/js/functions.js" charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
  </body>

</html>
