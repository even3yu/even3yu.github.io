<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Tensorflow 模型部署</title>
    <meta name="description" content="  训练好深度学习模型后可以通过 Tensorflow Extended (TFX) 把模型部署为服务方便地使用.">

    <!-- 网站所有权验证 -->
    <meta name="baidu-site-verification" content="code-kzX4R1yDEi" />
    <meta name="google-site-verification" content="kj0sMKl0iZFsV2KPqmN9OJ3S7aeCrJnNYAOTpJzXCz4" />
    <meta name="msvalidate.01" content="C9A829578EE81A43ECA102B601A5E052" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/css/zui.min.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/2019/12/22/Tensorflow-Serving-Deploy/">
    <link rel="alternate" type="application/rss+xml" title="Jarvis' Blog (总有美丽的风景让人流连)" href="http://localhost:4000/feed.xml ">


    <script>
    // 百度统计代码
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?b9d127980a49e998bbedb8aab536a81d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    <script>
    // google analytics
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-108096001-2', 'auto');
      ga('send', 'pageview');

    </script>





<!--  -->
    
<script type="text/javascript">
    var host = "jarvis73.com";
    if ((host == window.location.host) && (window.location.protocol != "https:"))
      window.location.protocol = "https";
</script>
</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/index.html" class="brand">Jarvis' Blog (总有美丽的风景让人流连)</a>
        <small>总有美丽的风景让人流连</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/index.html">
                    
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/wiki/">
                        
                            <i class="fa fa-book"></i>Wiki
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>Collections
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" post>
    <div class="left-jekyll">
        <h1>Tensorflow 模型部署</h1>
        <div class="label-custom">

            <div class="label-custom-card">
                <i class="fa fa-calendar"></i>2019-12-22
            </div>

            

            <div class="label-custom-card">
                <i class="fa fa-user"></i>Jarvis
                
            </div>

            <div class="label-custom-card">
                <i class="fa fa-key"></i>Post  
            </div>

            <div class="label-custom-card">
            


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Framework" title="Category: Framework" rel="category">Framework</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


            </div>

        </div>
        <hr>
        <article itemscope itemtype="http://schema.org/BlogPosting">
        <ul id="markdown-toc">
  <li><a href="#1-导出模型-tf-113-api" id="markdown-toc-1-导出模型-tf-113-api">1. 导出模型 (TF-1.13 API)</a></li>
  <li><a href="#2-部署模型-tf-20-api" id="markdown-toc-2-部署模型-tf-20-api">2. 部署模型 (TF-2.0 API)</a>    <ul>
      <li><a href="#21-服务端" id="markdown-toc-21-服务端">2.1 服务端</a></li>
      <li><a href="#22-客户端" id="markdown-toc-22-客户端">2.2 客户端</a></li>
      <li><a href="#23-使用老版本-nvidia-驱动" id="markdown-toc-23-使用老版本-nvidia-驱动">2.3 使用老版本 NVIDIA 驱动</a></li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>训练好深度学习模型后可以通过 Tensorflow Extended (TFX) 把模型部署为服务方便地使用.</p>
</blockquote>

<div class="polaroid">
    
    
    
    <img data-toggle="lightbox" src="/images/2019/12/tfx-hero.svg" data-caption="Tensowflow Extended (TFX)" />
    
        
        <div class="container">
            <p>图 1. Tensowflow Extended (TFX)</p>
        </div>
    
</div>

<h2 id="1-导出模型-tf-113-api">1. 导出模型 (TF-1.13 API)</h2>

<p>Tensorflow 目前统一的导出模型 API 为 SavedModel, 导出模型会把参数和模型结构分开存放 (ONNX 转换过来的参数和模型结构是合并在一个文件里的). 假设我们已经有一组训练好的模型参数, 使用如下的示例代码导出为 SavedModel 格式:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
</pre></td><td class="rouge-code"><pre><span class="c1"># Specify several directories
</span><span class="n">ckpt_dir</span> <span class="o">=</span> <span class="sh">"</span><span class="s">runs/tag</span><span class="sh">"</span>
<span class="n">export_dir</span> <span class="o">=</span> <span class="sh">"</span><span class="s">export_path/tag/1</span><span class="sh">"</span>
<span class="n">bs</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nc">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">serialized_tf_example</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">string</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">tf_example</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">feature_configs</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="nc">FixedLenFeature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
    <span class="n">tf_example</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">parse_example</span><span class="p">(</span><span class="n">serialized_tf_example</span><span class="p">,</span> <span class="n">feature_configs</span><span class="p">)</span>
    <span class="n">tf_example</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">tf_example</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">],</span> <span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">identity</span><span class="p">(</span><span class="n">tf_example</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">image</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># Do inference ................
</span>    <span class="c1"># pred = model(image)
</span>    <span class="c1"># .............................
</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="nc">Saver</span><span class="p">()</span>
    <span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="nf">latest_checkpoint</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">)</span>
    <span class="n">saver</span><span class="p">.</span><span class="nf">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ckpt</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Model restored.</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">builder</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nc">SavedModelBuilder</span><span class="p">(</span><span class="n">export_dir</span><span class="p">)</span>
    <span class="n">tensor_info_image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">build_tensor_info</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">tensor_info_output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">build_tensor_info</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="n">prediction_signature</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">signature_def_utils</span><span class="p">.</span><span class="nf">build_signature_def</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">:</span> <span class="n">tensor_info_image</span><span class="p">},</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">:</span> <span class="n">tensor_info_output</span><span class="p">},</span>
            <span class="n">method_name</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">signature_constants</span><span class="p">.</span><span class="n">PREDICT_METHOD_NAME</span><span class="p">))</span>

    <span class="n">builder</span><span class="p">.</span><span class="nf">add_meta_graph_and_variables</span><span class="p">(</span>
        <span class="n">sess</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">tag_constants</span><span class="p">.</span><span class="n">SERVING</span><span class="p">],</span>
        <span class="n">signature_def_map</span><span class="o">=</span><span class="p">{</span>
            <span class="sh">'</span><span class="s">serving_default</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">prediction_signature</span><span class="p">,</span>
        <span class="p">})</span>

    <span class="n">builder</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">as_text</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Done exporting!</span><span class="sh">'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>保存下来的目录结构如下所示. 注意我们增加了 <code class="language-plaintext highlighter-rouge">1</code> 作为子目录, 方便进行版本控制, 这表示该文件夹下是版本 <code class="language-plaintext highlighter-rouge">1</code> 的模型. 其中参数的保存格式和我们训练时检查点的格式相同, 而模型是 <code class="language-plaintext highlighter-rouge">protobuf</code> 的格式保存的. <code class="language-plaintext highlighter-rouge">*.pbtxt</code> 表示保存为文本格式, <code class="language-plaintext highlighter-rouge">*.pb</code> 表示保存为二进制格式.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>export_path/
└── tag
    └── 1
        ├── saved_model.pbtxt
        └── variables
            ├── variables.data-00000-of-00001
            └── variables.index
</pre></td></tr></tbody></table></code></pre></div></div>

<p>接下来对上面的代码进行分析. 为了服务端和客户端通信的方便, 客户端需要把待推断的数据通过 <code class="language-plaintext highlighter-rouge">protobuf</code> 编码为字符串, 从而服务端需要从字符串还原数据(如一幅图像). 因此构建的推断计算图入口为一个占位符接收字符串 <code class="language-plaintext highlighter-rouge">tf.string</code>, 并使用 <code class="language-plaintext highlighter-rouge">tf.FixedLenFeature()</code> 和 <code class="language-plaintext highlighter-rouge">tf.parse_example</code> 这两个 API 对 <code class="language-plaintext highlighter-rouge">protobuf</code> 格式的数据进行解码, 最后使用 <code class="language-plaintext highlighter-rouge">tf.reshape</code> 把数据重构为 4D 的张量用于神经网络. <code class="language-plaintext highlighter-rouge">tf.identity</code> 只是用于创建一个节点来标明图像, 无其他用处.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">serialized_tf_example</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">string</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">tf_example</span><span class="sh">"</span><span class="p">)</span>
<span class="n">feature_configs</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="nc">FixedLenFeature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
<span class="n">tf_example</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">parse_example</span><span class="p">(</span><span class="n">serialized_tf_example</span><span class="p">,</span> <span class="n">feature_configs</span><span class="p">)</span>
<span class="n">tf_example</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">tf_example</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">],</span> <span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">identity</span><span class="p">(</span><span class="n">tf_example</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">image</span><span class="sh">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>得到图像之后就可以构建核心计算图, 并导入先前训练好的模型参数. 这一段可以灵活的使用 Tensorflow 的各种 API. 唯一要注意的是最好使用已经提供的网络层或数学函数, 而使用 <code class="language-plaintext highlighter-rouge">tf.py_func</code> 这类函数构造的层可能会出问题 (未研究过, 遇到再写).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="nc">Saver</span><span class="p">()</span>
<span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="nf">latest_checkpoint</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">)</span>
<span class="n">saver</span><span class="p">.</span><span class="nf">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ckpt</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Model restored.</span><span class="sh">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>然后创建 <code class="language-plaintext highlighter-rouge">SavedModel</code> 构造器 <code class="language-plaintext highlighter-rouge">SavedModelBuilder</code>. 同时使用 <code class="language-plaintext highlighter-rouge">build_tensor_info</code> 函数获取输入和输出张量的协议. 协议的类型是 <code class="language-plaintext highlighter-rouge">tensorflow.core.protobuf.meta_graph_pb2.TensorInfo</code>, 可以直接打印出来查看.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre></td><td class="rouge-code"><pre><span class="n">builder</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nc">SavedModelBuilder</span><span class="p">(</span><span class="n">export_dir</span><span class="p">)</span>
<span class="n">tensor_info_image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">build_tensor_info</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">tensor_info_output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">build_tensor_info</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">tensor_info_image</span><span class="p">)</span>

<span class="c1">#　打印的结果
# name: "image:0"
# dtype: DT_FLOAT
# tensor_shape {
#   dim {
#     size: 1
#   }
#   dim {
#     size: 224
#   }
#   dim {
#     size: 224
#   }
#   dim {
#     size: 3
#   }
# }
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>创建模型签名. 然后使用 <code class="language-plaintext highlighter-rouge">builder</code> 把当前会话中的计算图, 参数和模型签名绑定.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="n">prediction_signature</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">signature_def_utils</span><span class="p">.</span><span class="nf">build_signature_def</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">:</span> <span class="n">tensor_info_image</span><span class="p">},</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">:</span> <span class="n">tensor_info_output</span><span class="p">},</span>
        <span class="n">method_name</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">signature_constants</span><span class="p">.</span><span class="n">PREDICT_METHOD_NAME</span><span class="p">))</span>

<span class="n">builder</span><span class="p">.</span><span class="nf">add_meta_graph_and_variables</span><span class="p">(</span>
    <span class="n">sess</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">saved_model</span><span class="p">.</span><span class="n">tag_constants</span><span class="p">.</span><span class="n">SERVING</span><span class="p">],</span>
    <span class="n">signature_def_map</span><span class="o">=</span><span class="p">{</span>
        <span class="sh">'</span><span class="s">serving_default</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">prediction_signature</span><span class="p">,</span>
    <span class="p">})</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>保存模型.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">builder</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">as_text</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Done exporting!</span><span class="sh">'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="2-部署模型-tf-20-api">2. 部署模型 (TF-2.0 API)</h2>

<p>由于模型已经按照 <code class="language-plaintext highlighter-rouge">protobuf</code> 的格式保存, 因此我们可以用任意版本的 Tensorflow 使用. 这里我们直接采用 Tensorflow 2.0 的 API.</p>

<h3 id="21-服务端">2.1 服务端</h3>

<p>Tensorflow 可以部署为仅使用 CPU, 但没有意义. 因此只讨论 GPU 版本的部署. 由于 Tensorflow 官方强烈建议在 Docker 中使用 <code class="language-plaintext highlighter-rouge">Tensorflow Serving</code>, 而 Docker 中使用主机的 GPU 需要 <code class="language-plaintext highlighter-rouge">Nvidia-Docker</code> 的支持, 但 NVIDIA 官方表明不支持在 Windows 中使用 <code class="language-plaintext highlighter-rouge">Nvidia-Docker</code>, 因此基于 Tensorflow-GPU 的模型部署只能在 Linux 系统上进行了.</p>

<p>服务端部署支持两种 API:</p>
<ul>
  <li>Client REST API</li>
  <li>gRPC API</li>
</ul>

<p>第一种基于 Json 格式进行数据传输, 第二种基于 Google 的 <code class="language-plaintext highlighter-rouge">protobuf</code> 格式进行数据传输. 第一种在 <a href="https://www.tensorflow.org/tfx/serving/docker">Tensorflow 官网</a>有介绍, 我们这里主要讨论第二种.</p>

<ol>
  <li>更新 Nvidia 驱动到最新版本. 这一步可以避免很多麻烦.</li>
  <li>安装 Docker. <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/">Link</a></li>
  <li>安装 nvidia-docker2. <a href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)">Link</a></li>
  <li>重启 Docker.</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nb">sudo </span>systemctl daemon-reload
<span class="nb">sudo </span>systemctl restart docker
</pre></td></tr></tbody></table></code></pre></div></div>
<ol>
  <li>拉取 tensorflow-serving 容器</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>docker pull tensorflow/serving:latest-gpu
</pre></td></tr></tbody></table></code></pre></div></div>

<p>接下来我们下载 Tensorflow 官方提供的示例程序.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="nb">mkdir</span> <span class="nt">-p</span> /tmp/tfserving
<span class="nb">cd</span> /tmp/tfserving
git clone https://github.com/tensorflow/serving
</pre></td></tr></tbody></table></code></pre></div></div>

<p>然后运行示例程序.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>docker run <span class="nt">--runtime</span><span class="o">=</span>nvidia <span class="nt">--rm</span> <span class="nt">-p</span> 8500:8500 <span class="nt">-p</span> 8501:8501 <span class="nt">-v</span> <span class="s2">"/tmp/tfserving/serving/tensorflow_serving/servables/tensorflow/testdata/saved_model_half_plus_two_gpu:/models/half_plus_two"</span> <span class="nt">-e</span> <span class="nv">MODEL_NAME</span><span class="o">=</span>half_plus_two <span class="nt">-t</span> tensorflow/serving:latest-gpu &amp;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>其中端口 8501 用于 REST API, 8500 端口用于 gRPC API. 其他参数的含义参考 Docker 的文档, 本文不详细展开.</p>

<h3 id="22-客户端">2.2 客户端</h3>

<p>服务端启动之后, 可以通过网址</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>http://localhost:8501/v1/models/half_plus_two/metadata
</pre></td></tr></tbody></table></code></pre></div></div>

<p>来查看服务端是否正常开启, 该网址会显示模型签名 (参考上面构造签名的代码). 接下来编写基于 gRPC 数据传输格式的客户端程序.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">grpc</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow_serving.apis</span> <span class="kn">import</span> <span class="n">predict_pb2</span>
<span class="kn">from</span> <span class="n">tensorflow_serving.apis</span> <span class="kn">import</span> <span class="n">prediction_service_pb2_grpc</span>

<span class="k">def</span> <span class="nf">client</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="sh">"</span><span class="s">localhost</span><span class="sh">"</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8500</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
    <span class="n">bs</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">numpy_array</span><span class="p">.</span><span class="n">shape</span>

    <span class="n">channel</span> <span class="o">=</span> <span class="n">grpc</span><span class="p">.</span><span class="nf">insecure_channel</span><span class="p">(</span><span class="sh">'</span><span class="s">{host}:{port}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">port</span><span class="p">))</span>
    <span class="n">stub</span> <span class="o">=</span> <span class="n">prediction_service_pb2_grpc</span><span class="p">.</span><span class="nc">PredictionServiceStub</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>

    <span class="n">request</span> <span class="o">=</span> <span class="n">predict_pb2</span><span class="p">.</span><span class="nc">PredictRequest</span><span class="p">()</span>
    <span class="n">request</span><span class="p">.</span><span class="n">model_spec</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">half_plus_two</span><span class="sh">"</span>
    <span class="n">request</span><span class="p">.</span><span class="n">model_spec</span><span class="p">.</span><span class="n">signature_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">serving_default</span><span class="sh">"</span>
    <span class="n">request</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">].</span><span class="nc">CopyFrom</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">make_tensor_proto</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]))</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">stub</span><span class="p">.</span><span class="nc">Predict</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">pred</span><span class="sh">"</span><span class="p">].</span><span class="n">int64_val</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">return</span> <span class="n">result</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="23-使用老版本-nvidia-驱动">2.3 使用老版本 NVIDIA 驱动</h3>

<p>官方的 Docker <code class="language-plaintext highlighter-rouge">tensorflow/serving:latest-gpu</code> 是根据 10.1 版本的 CUDA 版本创建的, 只能用于高版本的显卡驱动. 有时不方便更新主机显卡驱动, 此时要想使用 <code class="language-plaintext highlighter-rouge">tensorflow/serving</code> 的 Docker 则需要创建自己的 Docker 镜像. 假设我们主机的显卡驱动是 396.36 版本 (对应的 CUDA 版本最高为 9.2.88, 为了保险我们准备使用 9.0 版本的 CUDA). 从 <code class="language-plaintext highlighter-rouge">tensorflow/serving</code> 的 <a href="(https://github.com/tensorflow/serving/tree/master/tensorflow_serving/tools/docker)">docker 工具页面</a> 下载 <code class="language-plaintext highlighter-rouge">Dockerfile.devel-gpu</code> 和 <code class="language-plaintext highlighter-rouge">Dockerfile.gpu</code> 两个文件.</p>

<p>修改 <code class="language-plaintext highlighter-rouge">Dockerfile.devel-gpu</code>:</p>

<div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="c"># 选择基础镜像, 基础镜像需要根据操作系统版本和选定的cuda版本选择. </span>
<span class="c"># 可使用的基础镜像可以从 [DockerHub](https://hub.docker.com/r/nvidia/cuda/tags) 查询</span>
<span class="c"># FROM nvidia/cuda:10.0-base-ubuntu16.04 as base_build 修改为</span>
<span class="k">FROM</span><span class="w"> </span><span class="s">nvidia/cuda:9.0-base-ubuntu16.04</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="s">base_build</span>

<span class="c"># ......</span>

<span class="c"># CUDNN 的版本不用改, 因为和 CUDA 9 是兼容的</span>
<span class="k">ENV</span><span class="s"> CUDNN_VERSION=7.4.1.5</span>

<span class="c"># 然后把整个文档里的 10-0 和 10.0 全部修改为 9-0 和 9.0, 其他 CUDA 版本可以类似的修改.</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>修改完成后在终端使用 Dockerfile 构建镜像 (注意 docker build 命令末尾的点不能丢, 点表示构建路径为当前文件夹):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="nb">mkdir </span>tfs-devel
<span class="nb">mv </span>Dockerfile.devel-gpu tfs-devel
<span class="nb">cd </span>tfs-devel
docker build <span class="nt">-t</span> tensorflow/serving:latest-devel-gpu-cuda9.0 <span class="nb">.</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>接下来修改 <code class="language-plaintext highlighter-rouge">Dockerfile.gpu</code>:</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="k">ARG</span><span class="s"> TF_SERVING_VERSION=latest</span>
<span class="c"># 指定基础镜像为我们修改过的镜像</span>
<span class="c"># ARG TF_SERVING_BUILD_IMAGE=tensorflow/serving:${TF_SERVING_VERSION}-devel-gpu</span>
<span class="k">ARG</span><span class="s"> TF_SERVING_BUILD_IMAGE=tensorflow/serving:${TF_SERVING_VERSION}-devel-gpu-cuda9.0</span>

<span class="k">FROM</span><span class="w"> </span><span class="s">${TF_SERVING_BUILD_IMAGE}</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="s">build_image</span>
<span class="c"># 类似的修改</span>
<span class="c"># FROM nvidia/cuda:10.0-base-ubuntu16.04</span>
<span class="k">FROM</span><span class="s"> nvidia/cuda:9.0-base-ubuntu16.04</span>

<span class="c"># 然后把整个文档里的 10-0 和 10.0 全部修改为 9-0 和 9.0, 其他 CUDA 版本可以类似的修改.</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>最后构建第二个镜像, 可以看到第二个镜像是在第一个镜像的基础上构建的. 仍然要注意最后的点.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="nb">mkdir </span>tfs
<span class="nb">mv </span>Dockerfile.gpu tfs
<span class="nb">cd </span>tfs
docker build <span class="nt">-t</span> tensorflow/serving:latest-gpu-cuda9.0 <span class="nb">.</span>
</pre></td></tr></tbody></table></code></pre></div></div>

        </article>
        <hr>

        <!-- 
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
         -->

        <div class="post-recent">
    <div class="pre">
        
        <p><strong>上一篇</strong> <a href="/2019/08/10/Few-Shot-Learning/">小样本学习: 基础 (Few-Shot Learning: Basic)</a></p>
        
    </div>
    <div class="nex">

        
        <p><strong>下一篇</strong> <a href="/2019/12/26/Meta-Learning-Tutorial/">元学习简介 (Meta-Learning: Tutorial)</a></p>
        
    </div>
</div>


        <!-- <h2 id="comments">Comments</h2>
        



 -->


    </div>
    <button class="anchor"><i class="fa fa-anchor"></i></button>
    <div class="right-jekyll">
        <div class="wrap">

            <!-- Content -->
            <div class="side content">
                <div>
                    Content
                </div>
                <ul id="content-side" class="content-ul">
                    
                    <li><a href="#comments">Comments</a></li>
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <!-- <div class="side">bbbb</div> -->
        </div>
    </div>
</div>
<script>
/**
 * target _blank
 */
(function() {
    var aTags = document.querySelectorAll('article a:not([id]):not([class])')
    for (var i = 0; i < aTags.length; i++) {
        if (aTags[i].getAttribute('href').startsWith('#'))
        {
            continue
        }
        aTags[i].setAttribute('target', '_blank')
    }
}());
</script>
<script src="/js/pageContent.js " charset="utf-8"></script>

    <footer class="site-footer">


    <div class="wrapper">

        <p class="contact">
            联系我: 
            <a href="https://github.com/jarvis73" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:zjw.math@qq.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>   
            <a href="https://www.zhihu.com/people/lin-xi-1-1" title="Zhihu"><i class="iconfont icon-daoruzhihu"></i></a>      
        </p>
        <p>
            <i class="fa fa-eye" style="padding-right: 2px;"></i> 访问量: <span id="busuanzi_value_site_pv"></span>次 | <i class="fa fa-user" style="padding-right: 2px;"></i> 访客数<span id="busuanzi_value_site_uv"></span>人次
        </p>
        <p class="power">
            网站支持 <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a> | 主题支持 <a href="https://github.com/Gaohaoyang/gaohaoyang.github.io">HyG</a> & <a href="https://github.com/Jarvis73/jarvis73.github.io">Jarvis73</a>
        </p>
        <p>
            <img src="/images/misc/beian.png" style="padding-right: 2px; padding-bottom: 4px; vertical-align: middle;" /> <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo" class="beian" >浙公网安备 33010602011353号 | </a>
            <a target="_blank" href="https://beian.miit.gov.cn/" class="beian">浙ICP备2020038513号-1</a>
        </p>
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script type='text/javascript' src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"></script>
    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/lib/jquery/jquery.js" charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/js/zui.min.js" charset="utf-8"></script>
    <script src="/js/index_page.js" charset="utf-8"></script>
    <script src="/js/functions.js" charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
  </body>

</html>
