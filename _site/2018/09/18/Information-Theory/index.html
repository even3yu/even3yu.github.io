<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>机器学习(一): 信息论初步</title>
    <meta name="description" content="">

    <!-- 网站所有权验证 -->
    <meta name="baidu-site-verification" content="code-kzX4R1yDEi" />
    <meta name="google-site-verification" content="kj0sMKl0iZFsV2KPqmN9OJ3S7aeCrJnNYAOTpJzXCz4" />
    <meta name="msvalidate.01" content="C9A829578EE81A43ECA102B601A5E052" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/css/zui.min.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/2018/09/18/Information-Theory/">
    <link rel="alternate" type="application/rss+xml" title="Jarvis' Blog (总有美丽的风景让人流连)" href="http://localhost:4000/feed.xml ">


    <script>
    // 百度统计代码
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?b9d127980a49e998bbedb8aab536a81d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    <script>
    // google analytics
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-108096001-2', 'auto');
      ga('send', 'pageview');

    </script>



<script>
window.MathJax = {
  tex: {
    inlineMath: [["$$ "," $$"],["\\(","\\)"]],
    processEscapes: true,
    tags: "all",
    macros: {
      bm: ["{\\boldsymbol #1}",1]
    },
    packages: {'[+]': ['noerrors']}
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
  loader: {
    load: ['input/asciimath', '[tex]/noerrors']
  }
};
</script>
<script async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js" id="MathJax-script">
</script>
<!-- src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> -->



<!--  -->
    
<script type="text/javascript">
    var host = "jarvis73.com";
    if ((host == window.location.host) && (window.location.protocol != "https:"))
      window.location.protocol = "https";
</script>
</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/index.html" class="brand">Jarvis' Blog (总有美丽的风景让人流连)</a>
        <small>总有美丽的风景让人流连</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/index.html">
                    
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/wiki/">
                        
                            <i class="fa fa-book"></i>Wiki
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>Collections
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" post>
    <div class="left-jekyll">
        <h1>机器学习(一): 信息论初步</h1>
        <div class="label-custom">

            <div class="label-custom-card">
                <i class="fa fa-calendar"></i>2018-09-18
            </div>

            
            <div class="label-custom-card">
                <i class="fa fa-pencil"></i>2019-04-08
            </div>
            

            <div class="label-custom-card">
                <i class="fa fa-user"></i>Jarvis
                
            </div>

            <div class="label-custom-card">
                <i class="fa fa-key"></i>Post  
            </div>

            <div class="label-custom-card">
            


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#机器学习" title="Category: 机器学习" rel="category">机器学习</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


            </div>

        </div>
        <hr>
        <article itemscope itemtype="http://schema.org/BlogPosting">
        <ul id="markdown-toc">
  <li><a href="#1-信息量和熵" id="markdown-toc-1-信息量和熵">1. 信息量和熵</a></li>
  <li><a href="#2-kl-散度" id="markdown-toc-2-kl-散度">2. KL 散度</a></li>
  <li><a href="#3-互信息" id="markdown-toc-3-互信息">3. 互信息</a>    <ul>
      <li><a href="#连续随机变量的互信息" id="markdown-toc-连续随机变量的互信息">连续随机变量的互信息</a></li>
    </ul>
  </li>
  <li><a href="#参考" id="markdown-toc-参考">参考</a></li>
</ul>

<p>我们通常提到信息论(information theorey)时一般在谈论如何以更紧凑的方式表示数据(比如<strong>数据压缩</strong>或<strong>源编码</strong>), 或者在数据传输和存储时减少误差. 乍一看和机器学习及概率论并无关系, 但他们有着密切的联系. 比如在压缩数据时, 往往使用短的编码词编码高频词汇, 长的编码词编码低频词汇; 反之解码时需要一个好的概率模型来确定哪种原始组合的概率更高.</p>

<div class="polaroid">
    
    
    
    <img data-toggle="lightbox" src="/images/MLPP/Shannon.jpg" data-caption="Claude Shannon 1916-2001" />
    
        
        <div class="container">
            <p>图 1. Claude Shannon 1916-2001</p>
        </div>
    
</div>

<h2 id="1-信息量和熵">1. 信息量和熵</h2>

<blockquote>
  <p><strong>定义:</strong> 分布为 \(p\) 的随机变量 \(X\) 取值为 \(x\) 的<strong>信息量(information content)</strong>定义为</p>

\[\mathbf{I}_X(x) := \log{\frac1{p_X(x)}} = -\log{p_X(x)}\]

</blockquote>

<p>因此概率越小的事件, 信息量越大. 进而, 熵可以定义为随机变量 \(X\) 的平均信息量(即信息量的期望).</p>

<blockquote>
  <p><strong>定义:</strong> 分布为 \(p\) 的随机变量 \(X\) 的熵是不确定性的一种度量, 记为 \(\mathbb{H}(X)\) 或 \(\mathbb{H}(p)\) . 特别的, 对一个有着 \(K\) 个取值的离散随机变量, <strong>熵(entropy)</strong>可以定义为</p>

\[\mathbb{H}(X) := -\sum_{k=1}^Kp(X=k)\log{p(X=k)} = \mathbb{E}(\mathbf{I}(X))\]

</blockquote>

<p><strong>定理:</strong> \(\mathbb{H}(X)\leq \log{K}\), 当且仅当 \(X\) 是离散均匀分布时等号成立.</p>

<p>该定理可以作为下面信息不等式的推论得出. 从定理中容易知道离散分布的最大熵为 \(\mathbb{H}(X)=\log{K}\) . 特别地, \(K=2\) 时得到<strong>二值熵</strong> \(\mathbb{H}(X)=-(\theta\log{\theta}+(1-\theta)\log{(1-\theta)})\) , 其中 \(\theta\) 为成功概率(相应的 \(1-\theta\) 为失败概率).</p>

<blockquote>
  <p><strong>定义:</strong> 给定随机变量 \(X=x\), 随机变量 \(Y\) 的<strong>条件熵(conditional entropy)</strong>定义为</p>

\[\mathbb{H}(Y\lvert X=x) := -\sum_{y\in\mathcal{Y}}p(y\lvert x)\log{p(y\lvert x)}.\]

  <p>进一步, 给定随机变量 \(X\), 随机变量 \(Y\) 的条件熵定义为</p>

\[\mathbb{H}(Y\lvert X) := -\sum_{x\in\mathcal{X}}p(x)\mathbb{H}(Y\lvert X=x) = -\sum_{x\in\mathcal{X},y\in\mathcal{Y}}p(x, y)\log{p(y\lvert x)}\]

</blockquote>

<h2 id="2-kl-散度">2. KL 散度</h2>

<p>一个通常用于度量两个概率分布 \(p\) 和 \(q\) 的差异大小的指标就是 <strong>KL 散度(Kullback-Leibler divergence)</strong> 或称为<strong>相对熵</strong>.</p>

<blockquote>
  <p><strong>定义:</strong> 离散形式</p>

\[\mathbb{KL}(p\lVert q) := \sum_{k=1}^Kp_k\log{\frac{p_k}{q_k}}\]

  <p>连续形式</p>

\[\mathbb{KL}(p\lVert q) := \int_{\Omega} p(x)\log{\frac{p(x)}{q(x)}}\,dx\]

</blockquote>

<p>注意, KL 散度不是对称的, 所以并不是一种距离度量. 把 KL 散度展开为两项</p>

\[\mathbb{KL}(p\lVert q)=\sum_kp_k\log{p_k} - \sum_kp_k\log{q_k} = -\mathbb{H}(p) + \mathbb{H}(p, q)\]

<p>其中我们把 \(\mathbb{H}(p, q)\) 称为<strong>交叉熵</strong>. 交叉熵是使用模型 \(q\) 编码来自于分布 \(p\) 的数据所需要的平均位数, 从而”正规”熵 \(\mathbb{H}(p)=\mathbb{H}(p, p)\) 即是使用正确模型编码所需要的位数, 所以 KL 散度可以理解为使用模型 \(q\) 编码来自于分布 \(p\) 的数据所<font color="red">额外</font>需要的位数.</p>

<p><strong>定理(信息不等式):</strong> \(\mathbb{KL}(p\lVert q)\geq 0\), 当且仅当 \(p=q\) 时等号成立.</p>

<p>可利用 Jensen 不等式</p>

\[f\left(\sum_{i=1}^n\lambda_ix_i\right)\leq\sum_{i=1}^n\lambda_if(x_i).\]

<p>证明上述定理, 证明略.</p>

<h2 id="3-互信息">3. 互信息</h2>

<p>考虑随机变量 \(X\) 和 \(Y\), 如果我们想知道这两者之间的关联性有多强, 一个直接的方法是计算他们的相关系数. 但是相关系数所反应的随机变量的相关性存在局限性, 如下图所示</p>

<div class="polaroid">
    
    
    
    <img data-toggle="lightbox" src="https://upload.wikimedia.org/wikipedia/commons/0/02/Correlation_examples.png" data-caption="Correlation Examples" />
    
        
        <div class="container">
            <p>图 2. Correlation Examples</p>
        </div>
    
</div>

<p>相关性相同的随机变量可以有着千奇百怪且截然不同的分布. 因此我们引入<strong>互信息(mutual information, MI)</strong></p>

<blockquote>
  <p><strong>定义:</strong> 对随机变量 \(X\) 和 \(Y\),</p>

\[\mathbb{I}(X; Y) := \mathbb{KL}(p(X, Y)\lVert p(X)p(Y))=\sum_x\sum_yp(x, y)\log{\frac{p(x, y)}{p(x)p(y)}}\]

  <p>显然 \(\mathbb{I}(X; Y)\geq 0\), 当且仅当 \(p(X, Y)=p(X)p(Y)\) 时取等号.</p>
</blockquote>

<p>这意味着 \(MI=0\) 当且仅当 \(X\) 和 \(Y\) 独立. 进一步我们有</p>

\[\mathbb{I}(X; Y)=\mathbb{H}(X) - \mathbb{H}(X\lvert Y) = \mathbb{H}(Y) - \mathbb{H}(Y\lvert X)\]

<p>其中 \(\mathbb{H}(Y\lvert X)=\sum_xp(x)\mathbb{H}(Y\lvert X=x)\) 称为<strong>条件熵</strong>, 利用贝叶斯公式上式容易证明.  有了条件熵, 我们就能对互信息做出直观的解释: <font color="red">观测到随机变量 $$ Y $$ 后随机变量 $$ X $$ 的熵减</font>, 反之亦然. 与互信息相关的另一概念是<strong>点互信息(pointwise mutual information, PMI)</strong></p>

<blockquote>
  <p><strong>定义:</strong> 对随机事件 \(x\) 和 \(y\),</p>

\[\text{PMI}(x, y) := \log{\frac{p(x, y)}{p(x)p(y)}}=\log{\frac{p(x\lvert y)}{p(x)}}=\log{\frac{p(y|x)}{p(y)}}\]

  <p>衡量了两个事件同时发生的概率.</p>
</blockquote>

<p>显然 \(X\) 和 \(Y\) 的 MI 是 PMI 的期望(从定义式中可以看出).</p>

<h3 id="连续随机变量的互信息">连续随机变量的互信息</h3>

<p>计算连续随机变量的互信息通常先对其进行离散, 然后得到区间的统计值后再采用离散 MI 的计算公式. 然而离散的步长对结果有显著的影响. 另一种方法是<strong>最大化信息系数(maximal information coefficient, MIC)</strong> , 即尝试多种区间大小, 然后取最大值</p>

<blockquote>
  <p><strong>定义:</strong></p>

\[\text{MIC} := \max_{x, y:xy&lt;B}\frac{\max_{G\in\mathcal{G}(x, y)}\mathbb{I}(X(G);Y(G))}{\log{\min(x, y)}}\]

  <p>其中 \(\mathcal{G}(x, y)\) 是一族大小为 \(x\times y\) 的网格点, \(X(G), Y(G)\) 表示网格上离散了的随机变量, \(B\) 是采样的区间数, 一个典型的值为 \(B=N^{0.6}\).</p>
</blockquote>

<p>可以证明 MIC 的范围是 \([0, 1]\) . 下面图 A 给出了 63566 个随机变量的相关系数 CC 和 MIC 的关系图, 图 B 给出了 CC 和 MI 的关系图.</p>

<div class="polaroid">
    
    
    
    <img data-toggle="lightbox" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3325791/bin/nihms358982f4.jpg" data-caption="MI-MIC-CC" />
    
        
        <div class="container">
            <p>图 3. MI-MIC-CC</p>
        </div>
    
</div>

<ul>
  <li>点 C 表示一组低 CC, 低 MIC 的随机变量, 可以看出他们是不相关的.</li>
  <li>点 D 和 H 表示两组高 CC(取绝对值), 高 MIC 的随机变量, 可以看出他们几乎存在线性相关性.</li>
  <li>点 E, F 和 G 表示三组低 CC, 高 MIC 的随机变量, 显然他们存在非线性的相关性, 但是此时 CC 无法反映出这种相关性, 而 MIC 仍然能较好的体现出来.</li>
  <li>图 I 中左侧的两幅图的噪声比右侧的两幅图更小</li>
</ul>

<h2 id="参考">参考</h2>

<p>[1] Machine Learning: A Probabilistic Perspective, Kevin P. Murphy, Chapter 2, Probability</p>

<p>[2] https://en.wikipedia.org/wiki/File:Correlation_examples.png</p>

<p>[3] Reshef D N, Reshef Y A, Finucane H K, et al. Detecting novel associations in large data sets[J]. science, 2011, 334(6062): 1518-1524.</p>

        </article>
        <hr>

        <!-- 
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
         -->

        <div class="post-recent">
    <div class="pre">
        
        <p><strong>上一篇</strong> <a href="/2018/05/27/FCN+RNN/">FCN+RNN 论文阅读笔记</a></p>
        
    </div>
    <div class="nex">

        
        <p><strong>下一篇</strong> <a href="/2018/09/25/CUDA-Computing/">GPU 编程 (一) -- CUDA 的安装和环境的配置</a></p>
        
    </div>
</div>


        <!-- <h2 id="comments">Comments</h2>
        



 -->


    </div>
    <button class="anchor"><i class="fa fa-anchor"></i></button>
    <div class="right-jekyll">
        <div class="wrap">

            <!-- Content -->
            <div class="side content">
                <div>
                    Content
                </div>
                <ul id="content-side" class="content-ul">
                    
                    <li><a href="#comments">Comments</a></li>
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <!-- <div class="side">bbbb</div> -->
        </div>
    </div>
</div>
<script>
/**
 * target _blank
 */
(function() {
    var aTags = document.querySelectorAll('article a:not([id]):not([class])')
    for (var i = 0; i < aTags.length; i++) {
        if (aTags[i].getAttribute('href').startsWith('#'))
        {
            continue
        }
        aTags[i].setAttribute('target', '_blank')
    }
}());
</script>
<script src="/js/pageContent.js " charset="utf-8"></script>

    <footer class="site-footer">


    <div class="wrapper">

        <p class="contact">
            联系我: 
            <a href="https://github.com/jarvis73" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:zjw.math@qq.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>   
            <a href="https://www.zhihu.com/people/lin-xi-1-1" title="Zhihu"><i class="iconfont icon-daoruzhihu"></i></a>      
        </p>
        <p>
            <i class="fa fa-eye" style="padding-right: 2px;"></i> 访问量: <span id="busuanzi_value_site_pv"></span>次 | <i class="fa fa-user" style="padding-right: 2px;"></i> 访客数<span id="busuanzi_value_site_uv"></span>人次
        </p>
        <p class="power">
            网站支持 <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a> | 主题支持 <a href="https://github.com/Gaohaoyang/gaohaoyang.github.io">HyG</a> & <a href="https://github.com/Jarvis73/jarvis73.github.io">Jarvis73</a>
        </p>
        <p>
            <img src="/images/misc/beian.png" style="padding-right: 2px; padding-bottom: 4px; vertical-align: middle;" /> <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo" class="beian" >浙公网安备 33010602011353号 | </a>
            <a target="_blank" href="https://beian.miit.gov.cn/" class="beian">浙ICP备2020038513号-1</a>
        </p>
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script type='text/javascript' src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"></script>
    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/lib/jquery/jquery.js" charset="utf-8"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/zui/1.9.2/js/zui.min.js" charset="utf-8"></script>
    <script src="/js/index_page.js" charset="utf-8"></script>
    <script src="/js/functions.js" charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
  </body>

</html>
